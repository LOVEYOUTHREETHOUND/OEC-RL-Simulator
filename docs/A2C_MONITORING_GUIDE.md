# A2Cè®­ç»ƒç›‘æ§æŒ‡å—

## æ¦‚è¿°

ä¸ºäº†æ›´å¥½åœ°åˆ¤æ–­A2Cæ¨¡å‹çš„æ”¶æ•›æƒ…å†µï¼Œæˆ‘ä»¬å¢å¼ºäº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŒ‡æ ‡è®°å½•å’Œå¯è§†åŒ–åŠŸèƒ½ã€‚ç°åœ¨ç³»ç»Ÿä¼šè®°å½•ä¸¤ç±»æ•°æ®ï¼š

1. **Episodeçº§åˆ«çš„ç¯å¢ƒäº¤äº’æŒ‡æ ‡** - æ¯ä¸ªepisodeç»“æŸæ—¶è®°å½•
2. **A2Cè®­ç»ƒæŒ‡æ ‡** - æ¯æ¬¡rolloutç»“æŸåè®°å½•ï¼ˆæ¯n_stepsä¸€æ¬¡ï¼‰

---

## ğŸ“Š è®°å½•çš„æŒ‡æ ‡

### 1. Episodeçº§åˆ«æŒ‡æ ‡ï¼ˆæŒ‰episodeç´¢å¼•ï¼‰

**æ–‡ä»¶ä½ç½®**: `results/logs/a2c/<run_name>/by_episode_reward.txt`

**æ ¼å¼**:
```
# episode reward feasible_rate success_rate mean_miou mean_latency episode_length
1 43.560000 0.760000 0.760000 0.633800 143.501500 100
2 42.840000 0.700000 0.700000 0.684800 158.833140 100
...
```

**å­—æ®µè¯´æ˜**:
- `episode`: Episodeç´¢å¼•ï¼ˆä»1å¼€å§‹ï¼‰
- `reward`: Episodeæ€»å¥–åŠ±
- `feasible_rate`: å¯è¡Œæ­¥éª¤å æ¯”ï¼ˆæ»¡è¶³å»¶è¿Ÿçº¦æŸçš„æ­¥éª¤æ¯”ä¾‹ï¼‰
- `success_rate`: æˆåŠŸç‡ï¼ˆå½“å‰ç­‰åŒäºfeasible_rateï¼‰
- `mean_miou`: Episodeå†…å¹³å‡mIoUï¼ˆåˆ†å‰²è´¨é‡æŒ‡æ ‡ï¼‰
- `mean_latency`: Episodeå†…å¹³å‡æ€»å»¶è¿Ÿï¼ˆç§’ï¼‰
- `episode_length`: Episodeé•¿åº¦ï¼ˆæ­¥æ•°ï¼‰

**TensorBoardæ ‡ç­¾** (æ¨ªè½´ä¸ºepisodeç´¢å¼•):
- `by_episode/episode_reward`
- `by_episode/episode_length`
- `by_episode/feasible_rate`
- `by_episode/success_rate`
- `by_episode/mean_miou`
- `by_episode/mean_latency`

---

### 2. A2Cè®­ç»ƒæŒ‡æ ‡ï¼ˆæŒ‰timestepsï¼‰

**æ–‡ä»¶ä½ç½®**: `results/logs/a2c/<run_name>/a2c_training_metrics.txt`

**æ ¼å¼**:
```
# timesteps n_updates policy_loss value_loss entropy_loss explained_variance learning_rate total_loss
32768 1 0.123456 0.234567 0.012345 0.567890 0.000300 0.370368
65536 2 0.112345 0.223456 0.011234 0.678901 0.000300 0.346035
...
```

**å­—æ®µè¯´æ˜**:
- `timesteps`: å½“å‰è®­ç»ƒæ­¥æ•°
- `n_updates`: ç­–ç•¥æ›´æ–°æ¬¡æ•°
- `policy_loss`: ç­–ç•¥æŸå¤±ï¼ˆè¶Šå°è¶Šå¥½ï¼Œä½†ä¸åº”ä¸º0ï¼‰
- `value_loss`: ä»·å€¼å‡½æ•°æŸå¤±ï¼ˆåº”é€æ¸ä¸‹é™å¹¶è¶‹ç¨³ï¼‰
- `entropy_loss`: ç†µæŸå¤±ï¼ˆé¼“åŠ±æ¢ç´¢ï¼Œåº”é€æ¸ä¸‹é™ä½†ä¿æŒéé›¶ï¼‰
- `explained_variance`: è§£é‡Šæ–¹å·®ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼Œè¡¨ç¤ºä»·å€¼å‡½æ•°æ‹Ÿåˆè´¨é‡ï¼‰
- `learning_rate`: å½“å‰å­¦ä¹ ç‡
- `total_loss`: æ€»æŸå¤±ï¼ˆpolicy_loss + vf_coef * value_loss - ent_coef * entropy_lossï¼‰

**TensorBoardæ ‡ç­¾** (æ¨ªè½´ä¸ºtimesteps):
- `train/policy_loss` (SB3åŸç”Ÿ)
- `train/value_loss` (SB3åŸç”Ÿ)
- `train/entropy_loss` (SB3åŸç”Ÿ)
- `train/explained_variance` (SB3åŸç”Ÿ)
- `train/learning_rate` (SB3åŸç”Ÿ)
- `train/n_updates` (SB3åŸç”Ÿ)
- `train/loss` (SB3åŸç”Ÿ)
- `a2c/policy_loss` (æˆ‘ä»¬çš„å‰¯æœ¬ï¼Œä¾¿äºåˆ†ç»„æŸ¥çœ‹)
- `a2c/value_loss`
- `a2c/entropy_loss`
- `a2c/explained_variance`
- `a2c/learning_rate`
- `a2c/n_updates`
- `a2c/total_loss`

---

### 3. å®æ—¶è®­ç»ƒæŒ‡æ ‡ï¼ˆæŒ‰timestepsï¼‰

**TensorBoardæ ‡ç­¾**:
- `train/step_reward_inst`: å½“å‰æ­¥çš„å³æ—¶å¥–åŠ±ï¼ˆVecEnvå¤šç¯å¢ƒå¹³å‡ï¼‰
- `train/step_reward_ma`: æ»‘åŠ¨çª—å£å¹³å‡å¥–åŠ±ï¼ˆé»˜è®¤çª—å£1000æ­¥ï¼‰
- `train/step_reward_ema`: æŒ‡æ•°ç§»åŠ¨å¹³å‡å¥–åŠ±ï¼ˆæ›´å¹³æ»‘çš„è¶‹åŠ¿ï¼‰

---

## ğŸ” å¦‚ä½•åˆ¤æ–­A2Cæ”¶æ•›

### å…³é”®æŒ‡æ ‡åŠå…¶æœŸæœ›è¶‹åŠ¿

#### 1. **ç­–ç•¥ä¾§æŒ‡æ ‡**

| æŒ‡æ ‡ | æœŸæœ›è¶‹åŠ¿ | è¯´æ˜ |
|------|---------|------|
| `policy_loss` | ä¸‹é™åè¶‹ç¨³ | ç­–ç•¥æ¢¯åº¦æŸå¤±ï¼Œåº”è¯¥é€æ¸å‡å°å¹¶ç¨³å®šåœ¨è¾ƒä½å€¼ |
| `entropy_loss` | é€æ¸ä¸‹é™ä½†ä¿æŒéé›¶ | ç†µæŸå¤±ï¼Œå¤ªä½ä¼šå¯¼è‡´è¿‡æ—©æ”¶æ•›åˆ°æ¬¡ä¼˜ç­–ç•¥ |
| `explained_variance` | è¶‹è¿‘1.0 | ä»·å€¼å‡½æ•°å¯¹å›æŠ¥çš„è§£é‡Šèƒ½åŠ›ï¼Œè¶Šæ¥è¿‘1è¶Šå¥½ |

#### 2. **ä»·å€¼ä¾§æŒ‡æ ‡**

| æŒ‡æ ‡ | æœŸæœ›è¶‹åŠ¿ | è¯´æ˜ |
|------|---------|------|
| `value_loss` | ä¸‹é™å¹¶è¶‹ç¨³ | ä»·å€¼å‡½æ•°æ‹Ÿåˆè¯¯å·®ï¼Œåº”æŒç»­ä¸‹é™ |

#### 3. **ç¯å¢ƒäº¤äº’æŒ‡æ ‡**

| æŒ‡æ ‡ | æœŸæœ›è¶‹åŠ¿ | è¯´æ˜ |
|------|---------|------|
| `episode_reward` | ä¸Šå‡å¹¶è¶‹ç¨³ | Episodeæ€»å¥–åŠ±ï¼Œåº”æŒç»­å¢é•¿ |
| `feasible_rate` | ä¸Šå‡å¹¶è¶‹ç¨³ | å¯è¡Œè§£æ¯”ä¾‹ï¼Œè¶Šé«˜è¶Šå¥½ |
| `mean_miou` | ä¸Šå‡ï¼ˆå¦‚æœè¶Šé«˜è¶Šå¥½ï¼‰ | åˆ†å‰²è´¨é‡ï¼Œå–å†³äºä»»åŠ¡ç›®æ ‡ |
| `mean_latency` | ä¸‹é™ï¼ˆå¦‚æœè¶Šä½è¶Šå¥½ï¼‰ | å¹³å‡å»¶è¿Ÿï¼Œå–å†³äºä¼˜åŒ–ç›®æ ‡ |
| `step_reward_ma` | ä¸Šå‡å¹¶è¶‹ç¨³ | å¹³æ»‘çš„å¥–åŠ±è¶‹åŠ¿ |

#### 4. **è®­ç»ƒåŠ¨æ€æŒ‡æ ‡**

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| `learning_rate` | å­¦ä¹ ç‡ï¼ˆå¦‚ä½¿ç”¨lr_scheduleä¼šå˜åŒ–ï¼‰ |
| `n_updates` | ç­–ç•¥æ›´æ–°æ¬¡æ•°ï¼Œåº”çº¿æ€§å¢é•¿ |

---

## ğŸ“ˆ ä½¿ç”¨TensorBoardæŸ¥çœ‹

### å¯åŠ¨TensorBoard

```bash
tensorboard --logdir results/logs/a2c
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ `http://localhost:6006`

### æ¨èçš„é¢æ¿é…ç½®

#### é¢æ¿1: è®­ç»ƒæŸå¤±
- `train/policy_loss`
- `train/value_loss`
- `train/entropy_loss`
- `train/loss`

#### é¢æ¿2: è®­ç»ƒè´¨é‡
- `train/explained_variance`
- `a2c/explained_variance`

#### é¢æ¿3: Episodeæ€§èƒ½
- `by_episode/episode_reward`
- `by_episode/feasible_rate`
- `by_episode/success_rate`

#### é¢æ¿4: å®æ—¶å¥–åŠ±
- `train/step_reward_inst`
- `train/step_reward_ma`
- `train/step_reward_ema`

#### é¢æ¿5: ä»»åŠ¡æŒ‡æ ‡
- `by_episode/mean_miou`
- `by_episode/mean_latency`

---

## ğŸš¨ æ”¶æ•›é—®é¢˜è¯Šæ–­

### é—®é¢˜1: å¥–åŠ±ä¸å¢é•¿
**å¯èƒ½åŸå› **:
- `explained_variance` < 0.5 â†’ ä»·å€¼å‡½æ•°æ‹Ÿåˆä¸å¥½
- `entropy_loss` è¿‡ä½ â†’ æ¢ç´¢ä¸è¶³
- `policy_loss` éœ‡è¡ â†’ å­¦ä¹ ç‡è¿‡é«˜

**è§£å†³æ–¹æ¡ˆ**:
- é™ä½å­¦ä¹ ç‡
- å¢åŠ  `ent_coef`ï¼ˆç†µç³»æ•°ï¼‰
- æ£€æŸ¥ç¯å¢ƒå¥–åŠ±è®¾è®¡

### é—®é¢˜2: è®­ç»ƒä¸ç¨³å®š
**å¯èƒ½åŸå› **:
- `value_loss` éœ‡è¡å‰§çƒˆ
- `policy_loss` çªç„¶å¢å¤§

**è§£å†³æ–¹æ¡ˆ**:
- é™ä½å­¦ä¹ ç‡
- å‡å° `n_steps`ï¼ˆæ›´é¢‘ç¹æ›´æ–°ï¼‰
- å¢åŠ  `vf_coef`ï¼ˆä»·å€¼å‡½æ•°æƒé‡ï¼‰

### é—®é¢˜3: è¿‡æ—©æ”¶æ•›
**å¯èƒ½åŸå› **:
- `entropy_loss` è¿‡å¿«é™è‡³æ¥è¿‘0
- `feasible_rate` åœæ»åœ¨è¾ƒä½æ°´å¹³

**è§£å†³æ–¹æ¡ˆ**:
- å¢åŠ  `ent_coef`
- ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡
- æ£€æŸ¥å¥–åŠ±å‡½æ•°æ˜¯å¦æœ‰å±€éƒ¨æœ€ä¼˜

---

## ğŸ“ æ–‡ä»¶ç»“æ„

è®­ç»ƒè¿è¡Œåï¼Œä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ç»“æ„ï¼š

```
results/logs/a2c/<run_name>/
â”œâ”€â”€ by_episode_reward.txt          # Episodeçº§åˆ«æŒ‡æ ‡
â”œâ”€â”€ a2c_training_metrics.txt       # A2Cè®­ç»ƒæŒ‡æ ‡
â”œâ”€â”€ tb/                             # TensorBoardæ—¥å¿—
â”‚   â””â”€â”€ A2C_1/
â”‚       â””â”€â”€ events.out.tfevents.*
â”œâ”€â”€ monitor/                        # Monitoræ—¥å¿—ï¼ˆSB3åŸç”Ÿï¼‰
â”‚   â”œâ”€â”€ monitor_0.csv
â”‚   â”œâ”€â”€ monitor_1.csv
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train_logs/                     # è¯¦ç»†è®­ç»ƒæ—¥å¿—ï¼ˆJSONLæ ¼å¼ï¼‰
â”‚   â”œâ”€â”€ train_ep_000001-000100.jsonl
â”‚   â””â”€â”€ ...
â””â”€â”€ train_plain_logs/               # äººç±»å¯è¯»è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ train_ep_000001-000100.log
    â””â”€â”€ ...
```

---

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### ä¿®æ”¹è®°å½•é¢‘ç‡

åœ¨ `scripts/train_a2c.py` ä¸­è°ƒç”¨ `build_callbacks` æ—¶ï¼š

```python
callbacks = build_callbacks(
    ...
    a2c_metrics_log_every=100,  # A2CæŒ‡æ ‡è®°å½•é¢‘ç‡ï¼ˆæ¯100æ­¥ï¼‰
    step_ma_log_every=200,      # æ­¥çº§å¥–åŠ±è®°å½•é¢‘ç‡
    ...
)
```

### ç¦ç”¨æŸäº›è®°å½•

```python
callbacks = build_callbacks(
    ...
    enable_a2c_metrics=False,        # ç¦ç”¨A2CæŒ‡æ ‡è®°å½•
    enable_episode_reward=False,     # ç¦ç”¨EpisodeæŒ‡æ ‡è®°å½•
    enable_step_reward_ma=False,     # ç¦ç”¨æ­¥çº§å¥–åŠ±è®°å½•
    ...
)
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **è®­ç»ƒåˆæœŸ**ï¼ˆå‰10-20%æ­¥æ•°ï¼‰:
   - é‡ç‚¹å…³æ³¨ `explained_variance` æ˜¯å¦å¿«é€Ÿä¸Šå‡
   - æ£€æŸ¥ `value_loss` æ˜¯å¦ä¸‹é™
   - ç¡®ä¿ `entropy_loss` ä¿æŒåœ¨åˆç†èŒƒå›´ï¼ˆä¸è¦å¤ªå¿«é™è‡³0ï¼‰

2. **è®­ç»ƒä¸­æœŸ**ï¼ˆ20-70%æ­¥æ•°ï¼‰:
   - å…³æ³¨ `episode_reward` æ˜¯å¦æŒç»­å¢é•¿
   - æ£€æŸ¥ `feasible_rate` æ˜¯å¦æå‡
   - ç›‘æ§ `policy_loss` æ˜¯å¦è¶‹ç¨³

3. **è®­ç»ƒåæœŸ**ï¼ˆ70-100%æ­¥æ•°ï¼‰:
   - ç¡®è®¤å„æŒ‡æ ‡æ˜¯å¦æ”¶æ•›ï¼ˆæ›²çº¿è¶‹äºå¹³ç¼“ï¼‰
   - æ£€æŸ¥ `explained_variance` æ˜¯å¦æ¥è¿‘1.0
   - è¯„ä¼°æœ€ç»ˆæ€§èƒ½æ˜¯å¦æ»¡è¶³è¦æ±‚

4. **å®šæœŸæ£€æŸ¥**:
   - æ¯éš”ä¸€æ®µæ—¶é—´æŸ¥çœ‹TensorBoard
   - å¯¹æ¯”ä¸åŒè¿è¡Œçš„æ›²çº¿
   - ä¿å­˜è¡¨ç°å¥½çš„checkpoint

---

## ğŸ“š å‚è€ƒèµ„æ–™

- [Stable-Baselines3 A2Cæ–‡æ¡£](https://stable-baselines3.readthedocs.io/en/master/modules/a2c.html)
- [A2Cç®—æ³•è®ºæ–‡](https://arxiv.org/abs/1602.01783)
- [TensorBoardä½¿ç”¨æŒ‡å—](https://www.tensorflow.org/tensorboard)

---

**æ›´æ–°æ—¥æœŸ**: 2025-12-19
**ç‰ˆæœ¬**: 1.0

